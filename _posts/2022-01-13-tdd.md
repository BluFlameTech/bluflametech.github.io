---
title: "It's Time For TDD To Evolve"
subtitle: It was a revolution. Now, it needs an evolution.
date: 2022-01-13T12:30:00-04:00
header:
    teaser: /assets/images/posts/tdd/tdd.jpg
categories:
- blog
tags:
- software development
- programming
- testing
---

TDD was heralded as a flow that created testable (and well tested) software. But it's also been derided for what some
perceive as test-induced damage. Here's how we can navigate a better path forward for Test Drive Development.

![TDD](/assets/images/posts/tdd/tdd.jpg)

_<small>Image by [Dmitry Kovalchuk](https://www.istockphoto.com/portfolio/DmitryKovalchuk?mediatype=illustration) on [iStock](https://www.istockphoto.com) by Getty Images</small>_

> We produce well-designed, well-tested, and well-factored code in small, verifiable steps.

-[James Shore](http://www.jamesshore.com/v2/books/aoad1/test_driven_development)

### What Is TDD?

TDD or Test Driven Development is a practice of software development that breaks software changes down into incremental
testable pieces. 

The aim of TDD is to _produce well-designed, well-tested, and well-factored code in small, verifiable steps._

[Fowler](https://martinfowler.com/bliki/TestDrivenDevelopment.html) describes TDD as a 3-step repeatable process.

1. Write a test for the next bit of functionality you want to add.
2. Write the functional code until the test passes.
3. Refactor both new and old code to make it well-structured.

Additionally, there are some core tenants behind TDD, like...

1. Mock most, if not all, interactions
2. Test based on the interface and expected use, not based on ease of implementation
3. Tests should be as granular as possible

### Where Did TDD Go Wrong?

The biggest criticism of TDD is that it can miss the metaphorical forrest through the trees. So much time and effort is
focused on building and testing small increments that unnecessary and even damaging work can become a side effect of
the TDD flow. David Heinemeier from Ruby on Rails and Basecamp [refers to this as test-induced damage](https://www.youtube.com/watch?v=JoTB2mcjU7w).

It should also be noted that in that same conversation with David Heinemeier, Kent Beck argues that TDD does not absolve you
from making prudent design decisions. It does, however, favor an evolutionary approach to design that complements well-tested software.
He further goes on to say that there is a question of granularity at play and one should be careful to embrace extremes in this regard.

This, in my opinion is a big part of the problem with TDD: granularity. Most of the literature on TDD seems to indicate that
tests, and therefore design and the software that follows only looks at a handful of lines of code at a time. That's all good and
fine for a small software library. But, what about a larger application? Keeping your head down and only looking at what
is front of you can have some serious consequences. And, as David Heinemeier pointed out, it can also lead to some very poor
design decisions.

### How TDD Can Be Saved

I'll acknowledge that the heading is a bit overly sensational. But sensational heading aside, let's also acknowledge that
TDD is derived from a ton of great prior work, like _program to an interface, not an implementation_ and work in _very small steps_,
just to name a couple.

And honestly, when you get right down to it, the parts of TDD that are deemed the most destructive are the dogmatic rules that people layer on top
of TDD. When Kent Beck described TDD in his book [Test Driven Development: By Example](https://www.amazon.com/gp/product/0321146530/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=0321146530&linkCode=as2&tag=martinfowlerc-20), 
he described it as having two simple rules.

* Write a failing automated test before you write any code.
* Remove duplication.

There is no mention of what or how to mock. There is no mention of extreme granularity. Just write tests before you write code and remove duplication.

It then follows that the real aim of TDD is to write testable software that is also well-tested software. Why? Because
we know that a side effect of poorly tested or untestable software is often pain in the form of a heavy maintenance burden, instability, and bugs... lots and lots of bugs.
That's not to say that well-tested software is well-designed, easy to maintain or that is immune to bugs. But poorly tested software, and
certainly software that is not testable is more likely to have the aforementioned undesirable traits.

#### Choosing a Level of Granularity

Increments of 10 lines of code or less can work well for some situations, and it can work very poorly for other situations.
If you are building a MVC application, it may work pretty poorly. Evidence for this is the example David Heinemeier gave in
the discussion above. I think this is one of those situation where you do what make sense. Bite off as little as is reasonable
to achieve some level of incremental value that gels with the context of the system or module in which you are working.

If you are working in a MVC application, it may be perfectly reasonable (and IMO preferred) to test at the controller
level like it's actually working. The prevalence and popularity of frameworks like Spring's MockMvc suggests that very approach.
Maybe it also tests other stuff in addition to the controller (e.g. the model and data interactions). That's OK!
Remember the goals: well-tested with tests based on usage, not implementation. What you don't want to happen is to
get so wrapped up in testing dogma that the software is negatively impacted.

#### Mocks

To mock or not to mock? That is the question. For granular unit tests, mocking is awesome! Mocks allow for the isolation
of software entities down to their interfaces. But, in the context of a framework that makes certain assumptions (e.g. Rails, Spring Boot, Django, etc.),
homegrown mocks can do more harm than good. Why? Because they aren't realistic. And, by mocking when you shouldn't, there is a real chance that you are
expending a lot of effort to get very little value.

#### Experiment

As surprising as it may be to some, software developers don't have all the answers up front. I know. It's hard to say it out loud.

The best approach might not always be clear and heads down incremental steps into the unknown just might lead off a cliff.
Ok for lemmings. Not so great for software.

It therefore follows that writing tests that influence design when you aren't sure what you could or should do is not a great approach.
At this point, one might conclude that a research spike or some such thing is in order. But sometimes, it's something small.
Sometimes, as they say, the devil is in the details. Sometimes, you just need to experiment. 

There is a myth or perhaps a stigma that experimentation is antithetical to TDD. It is not.

Continual experimentation is part of software development. And for me, it's also a big part of what makes software
development enjoyable. Experiment, figure out how to do it and then go back to your TDD flow.

#### Design

As stated above, TDD does not absolve you from making prudent design decisions. 

### TL;DR


